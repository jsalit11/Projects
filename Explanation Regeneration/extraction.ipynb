{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFQ5bvCCd0zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519645aa-b26e-4a18-9108-6acc7d849471"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logging = logging.getLogger(__name__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEKGuC1GeJsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f8b30a-803e-4353-a85c-63037bed89fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_dir = 'drive/My Drive/knowledge engineering/assignments/assignment_4/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIKEOdJukh7S"
      },
      "source": [
        "class ProcessTable:\n",
        "    def __init__(self, table, table_name):\n",
        "        self.table = table\n",
        "        self.table_name = table_name\n",
        "\n",
        "    def create_sentence(self, row):        \n",
        "        sentence = ' '.join(row[:-1])\n",
        "        sentence = sentence.lower()\n",
        "        return sentence\n",
        "    \n",
        "    def preprocess_row(self, row):\n",
        "        row = row.lower()\n",
        "        row = row.split('\\t')\n",
        "        row = [i for i in row if len(i) != 0]\n",
        "        id = row[-1].split('\\n')[0]\n",
        "        return row, id\n",
        "\n",
        "    def filter_words(self, sentence):\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        # filtered_words = [i for i in row[:-1] if i not in stop_words]\n",
        "        filtered_words = [i for i in sentence.split(' ') if i not in stop_words]\n",
        "        return filtered_words\n",
        "\n",
        "    def iterate_table(self):\n",
        "        new_table = []\n",
        "        for row in self.table[1:]:\n",
        "            row, id = self.preprocess_row(row)\n",
        "            sentence = self.create_sentence(row)\n",
        "            filtered_words = self.filter_words(sentence)\n",
        "            new_table.append([id, sentence, filtered_words, self.table_name, 'fact'])\n",
        "        return new_table\n",
        "\n",
        "    def main(self):\n",
        "        table = self.iterate_table()\n",
        "        return table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7K7Sf1Ajcm0"
      },
      "source": [
        "class EntryPoint:\n",
        "    def __init__(self, input_directory, output_directory):\n",
        "        self.input_directory = input_directory\n",
        "        self.output_directory = output_directory\n",
        "    \n",
        "    def get_tables(self):\n",
        "        file_list = os.listdir(self.input_directory)\n",
        "        return file_list\n",
        "\n",
        "    def load_table(self, file_path):        \n",
        "        with open(file_path) as f:\n",
        "            table = f.readlines()   \n",
        "        return table     \n",
        "\n",
        "    def iterate_tables(self):\n",
        "        sentence_node_table = [['fact_id:ID', 'fact', 'filtered_fact', 'table_name', \n",
        "                                ':LABEL']]\n",
        "        for file_name in self.get_tables():\n",
        "            if file_name.endswith('tsv'):\n",
        "                file_path = os.path.join(self.input_directory, file_name)\n",
        "                temp_sentence_node_table = self.load_table(file_path)\n",
        "                sentence_node_table.extend(ProcessTable(temp_sentence_node_table, \n",
        "                                                file_name.split('.')[0]).main())\n",
        "        return sentence_node_table\n",
        "\n",
        "    def to_dataframe(self, data):\n",
        "        data = pd.DataFrame(data)\n",
        "        data.columns = data.iloc[0]\n",
        "        data.drop(0, axis=0, inplace=True)\n",
        "        for column in data.columns:\n",
        "            if ':ID' in column:\n",
        "                data.drop_duplicates(column, inplace=True)\n",
        "        return data\n",
        "\n",
        "    def write_to_csv(self, file_name, data):\n",
        "        logging.info(f'Writing {file_name} to file')\n",
        "        file_path = os.path.join(self.output_directory, file_name)\n",
        "        data.to_csv(file_path, index=False)\n",
        "\n",
        "    def main(self):\n",
        "        sentence_node_table = self.iterate_tables()\n",
        "        shared_term_relationships = Relationships(sentence_node_table).main()\n",
        "        sentence_node_table = self.to_dataframe(sentence_node_table)\n",
        "        shared_term_relationships = self.to_dataframe(shared_term_relationships)\n",
        "        self.write_to_csv('sentence_node_table.csv', sentence_node_table)\n",
        "        self.write_to_csv('shared_term_relationships.csv', shared_term_relationships)\n",
        "        return sentence_node_table, shared_term_relationships"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62sGIoXPUZbe"
      },
      "source": [
        "class Relationships:\n",
        "    def __init__(self, table):\n",
        "        self.table = table\n",
        "\n",
        "    def iterate_table(self):\n",
        "        shared_terms_relationship = [[':START_ID', ':END_ID', ':TYPE', 'shared_term']]\n",
        "        for row in self.table[1:]:\n",
        "            for term in row[2]:\n",
        "                for row_2 in self.table[1:]:\n",
        "                    if term in row_2[2]:\n",
        "                        shared_terms_relationship.append([row[0], row_2[0], 'SHARED_TERM', term])\n",
        "        return shared_terms_relationship\n",
        "\n",
        "    def main(self):\n",
        "        return self.iterate_table()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLMzpmb3gCDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd5822b-4e64-48a9-d30c-660ecf1af1df"
      },
      "source": [
        "input_directory = os.path.join(base_dir, 'data/worldtree_full/tsv/tables')\n",
        "output_directory = os.path.join(base_dir, 'data/delta_files')\n",
        "sentence_node_table, shared_term_relationships = EntryPoint(\n",
        "                                    input_directory, \n",
        "                                    output_directory\n",
        "                                    ).main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Writing sentence_node_table.csv to file\n",
            "INFO:__main__:Writing shared_term_relationships.csv to file\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}