{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Joshua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "from statistics import mean \n",
    "from statistics import stdev\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from neo4j import GraphDatabase\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "logging.getLogger(\"gensim\").setLevel(logging.WARNING)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryDatabase:\n",
    "    def __init__(self, terms):\n",
    "        self.driver = GraphDatabase.driver(\n",
    "            \"bolt://localhost:7687\", \n",
    "            auth=(\"assn_4_data\", \"password\"))\n",
    "        self.terms = terms\n",
    "        self.query = self.query()\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def query_database(self):\n",
    "        with self.driver.session() as session:\n",
    "            query = session.write_transaction(self._create_and_return_query)\n",
    "        return query\n",
    "\n",
    "    def _create_and_return_query(self, tx):\n",
    "        result = tx.run(self.query)\n",
    "        return result.values()\n",
    "    \n",
    "    def query(self):\n",
    "        query = f\"\"\"\n",
    "                MATCH (f:fact)-[term:SHARED_TERM]-(f:fact)\n",
    "                WHERE [x IN {self.terms} WHERE x = term.shared_term]\n",
    "                RETURN f.fact, f.fact_id\n",
    "                \"\"\" \n",
    "        return query\n",
    "    \n",
    "    @staticmethod\n",
    "    def separate_results(results):\n",
    "        facts = [i[0] for i in results]\n",
    "        fact_ids = [i[1] for i in results]\n",
    "        return facts, fact_ids\n",
    "    \n",
    "    def main(self):\n",
    "        logging.info(f'Getting facts for term {self.terms}')\n",
    "        results = self.query_database()\n",
    "        self.close()  \n",
    "        facts, fact_ids = self.separate_results(results)\n",
    "        return facts, fact_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AskQuestion:\n",
    "    def __init__(self, question=None, directory=''):\n",
    "        self.questions_table_path = 'tsv/questionsAndExplanations.tsv'\n",
    "        self.questions_table = self.import_questions_table()\n",
    "        self.question = question\n",
    "        self.directory = directory\n",
    "        self.initiate_questions = {}\n",
    "        \n",
    "    def import_questions_table(self):\n",
    "        questions_table = pd.read_csv(self.questions_table_path, sep='\\t', encoding='latin-1')\n",
    "        return questions_table\n",
    "        \n",
    "    def get_question(self, sample):\n",
    "        questions = self.questions_table['question'].tolist()[sample]\n",
    "        return questions\n",
    "    \n",
    "    def get_explanation_ids(self, sample):\n",
    "        explanations_raw = self.questions_table['explanation'].tolist()[sample]\n",
    "        if explanations_raw is None:\n",
    "            raise Exception('Looks like we do not have an answer to this question, lets find another')\n",
    "        explanation_ids = []\n",
    "        for explanation in explanations_raw.split(' '):\n",
    "            explanation_ids.append(explanation.split('|')[0])\n",
    "        return explanation_ids\n",
    "    \n",
    "    def get_random_sample(self):\n",
    "        sample = random.sample(range(len(self.questions_table)), 1)[0]\n",
    "        return sample\n",
    "    \n",
    "    def parse_question(self, question):\n",
    "        question = question.split('?')[0].lower()\n",
    "        if self.initiate_questions['random_question']:\n",
    "            logging.info(f'Ok How about question: {question}')                \n",
    "        question = question.split('(a)')[0]\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = question.split(' ')        \n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        tokens = [word for word in tokens if word.isalpha()]\n",
    "        return tokens\n",
    "    \n",
    "    @staticmethod\n",
    "    def thinking():\n",
    "        responses = [\n",
    "            'Hmm... let me think about that one',\n",
    "            'That is a good question, the top results are',\n",
    "            'You are really asking the tough ones huh',\n",
    "            'What am I a machine, how am I supposed to know that? Lets see',\n",
    "            'Good question',\n",
    "            'Is that all you got?'\n",
    "        ]\n",
    "        response = random.sample(responses, 1)[0]\n",
    "        logging.info(response)\n",
    "        \n",
    "    def initiate_question(self):\n",
    "        logging.info('''Hello! How are you? I have mastered elementary school education. \n",
    "        Please ask me a question.''')\n",
    "        question = input('If you have a question, please ask otherwise respond \"no\".').lower()\n",
    "        if question.lower() == 'no':\n",
    "            question = None\n",
    "            logging.info('Okay let me find a good question for you.')\n",
    "            self.initiate_questions['random_question'] = True\n",
    "            score = input('Would you like to score it or just see responses?').lower()\n",
    "            if ('score' in score) or ('yes' in score):\n",
    "                self.initiate_questions['score'] = True\n",
    "            else:\n",
    "                self.initiate_questions['score'] = False\n",
    "        else:\n",
    "            self.initiate_questions['random_question'] = False\n",
    "            self.initiate_questions['score'] = False\n",
    "            return question\n",
    "        questions_to_ask = ['score', 'random_question']\n",
    "        for question_to_ask in questions_to_ask:\n",
    "            if question_to_ask not in self.initiate_questions:\n",
    "                logging.info('Lets start over because I missed a few details')\n",
    "                self.initiate_question()\n",
    "        self.thinking()\n",
    "        \n",
    "    def response(self, scores, explanation_ids=None):\n",
    "        facts = [i[0] for i in scores][:10]\n",
    "        if self.initiate_questions.get('random_question'):\n",
    "            if self.initiate_questions.get('score'):\n",
    "                self.score_question(scores, explanation_ids)\n",
    "            else:\n",
    "                logging.info('. '.join(facts))\n",
    "        else:\n",
    "            logging.info('. '.join(facts))\n",
    "                \n",
    "    def score_question(self, score, explanation_ids):\n",
    "        # Getting only top 20 facts\n",
    "        fact_ids = [i[1] for i in score][:20]\n",
    "        explanation_id_count = 0\n",
    "        for idx, explanation_id in enumerate(explanation_ids):            \n",
    "            explanation_id_flag = False\n",
    "            for fact_id in fact_ids:\n",
    "                if explanation_id == fact_id:\n",
    "                    logging.info(f'The explanation ID {explanation_id} was ranked at {idx + 1}')\n",
    "                    explanation_id_flag = True\n",
    "                    explanation_id_count += 1\n",
    "            if explanation_id_flag == False:\n",
    "                logging.info(f'The explanation ID {explanation_id} was not ranked at all')\n",
    "        response = self.explanation_id_count_response(explanation_id_count, explanation_ids)\n",
    "        logging.info(response)\n",
    "                    \n",
    "    @staticmethod\n",
    "    def explanation_id_count_response(explanation_id_count, explanation_ids):\n",
    "        metric = explanation_id_count / len(explanation_ids)\n",
    "        if metric >= 0.5:\n",
    "            response = f'{metric} is great'\n",
    "        elif metric > 0.8:\n",
    "            response = f'{metric}... wow. I think I am ready for middle school'\n",
    "        elif metric >= 0.3:\n",
    "            response = f'{metric} is not too bad'\n",
    "        elif metric < 0.3:\n",
    "            response = f'{metric} is really bad, I think I need to study more'\n",
    "        return response\n",
    "            \n",
    "    def main(self):                \n",
    "        question_response = self.initiate_question()\n",
    "        if question_response is not None:\n",
    "            explanation_ids = None\n",
    "            question = question_response            \n",
    "        else:\n",
    "            sample = self.get_random_sample()            \n",
    "            question = self.get_question(sample)\n",
    "            explanation_ids = self.get_explanation_ids(sample)\n",
    "        question_terms = self.parse_question(question)\n",
    "        facts, fact_ids = QueryDatabase(question_terms).main()\n",
    "        try:\n",
    "            scores = CalculateScores(self.directory).calculate_scores(facts, question_terms,\n",
    "                                                                     fact_ids)\n",
    "            self.response(scores, explanation_ids)\n",
    "            exit()\n",
    "        except:\n",
    "            raise Exception('Having trouble finding an answer, please ask another question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculateScores:\n",
    "    def __init__(self, directory=''):        \n",
    "        self.directory = directory\n",
    "    \n",
    "    def load_tfidf(self):\n",
    "        file_path = self.directory + 'mapping_files/tfidf.json'\n",
    "        with open(file_path) as f:\n",
    "            tfidf = json.load(f)\n",
    "        return tfidf\n",
    "    \n",
    "    def load_word_vectors(self):\n",
    "        file_path = self.directory + 'mapping_files/word2vec.wordvectors'\n",
    "        word_vectors = KeyedVectors.load(file_path)\n",
    "        return word_vectors\n",
    "        \n",
    "    def calculate_scores(self, facts, question_terms, fact_ids):\n",
    "        tfidf = self.load_tfidf()\n",
    "        word_vectors = self.load_word_vectors()\n",
    "        tfidf_scores = []\n",
    "        cosine_similarity_scores = []\n",
    "        for fact in facts:\n",
    "            tfidf_score = 0\n",
    "            cosine_similarity_score = 0\n",
    "            for token in fact.split(' '):\n",
    "                tfidf_score_temp = tfidf.get(token)\n",
    "                if tfidf_score_temp is None:\n",
    "                    tfidf_score_temp = 0\n",
    "                tfidf_score += tfidf_score_temp\n",
    "                cosine_similarity_score += self.calculate_cosine_similarity(question_terms\n",
    "                                                                    , token, word_vectors)\n",
    "            tfidf_score /= len(fact)\n",
    "            cosine_similarity_score /= len(fact)\n",
    "            fact = ' '.join(fact)\n",
    "            tfidf_scores.append(tfidf_score)\n",
    "            cosine_similarity_scores.append(cosine_similarity_score)\n",
    "        fact_scores = self.standardize_scores(facts, fact_ids, tfidf_scores, \n",
    "                                              cosine_similarity_scores)\n",
    "        sorted_facts = sorted(fact_scores, key=lambda x: x[-1], reverse=True)\n",
    "        return sorted_facts\n",
    "    \n",
    "    @staticmethod\n",
    "    def standardize_scores(facts, fact_ids, tfidf_scores, cosine_similarity_scores):\n",
    "        fact_scores = []\n",
    "        tfidf_scores_mean = mean(tfidf_scores)\n",
    "        tfidf_scores_stdev = stdev(tfidf_scores)\n",
    "        cosine_similarity_scores_mean = mean(cosine_similarity_scores)\n",
    "        cosine_similarity_scores_stdev = stdev(cosine_similarity_scores)\n",
    "        for i in range(len(facts)):\n",
    "            tfidf_zscore = (tfidf_scores[i] - tfidf_scores_mean) / tfidf_scores_stdev\n",
    "            cosine_similarity_zscore = (cosine_similarity_scores[i] - \\\n",
    "                                        cosine_similarity_scores_mean) / cosine_similarity_scores_stdev\n",
    "            agg_score = (tfidf_zscore + cosine_similarity_zscore) / 2\n",
    "            fact_scores.append([facts[i], fact_ids[i], tfidf_zscore, \n",
    "                                cosine_similarity_zscore, agg_score])    \n",
    "        return fact_scores\n",
    "        \n",
    "    @staticmethod\n",
    "    def calculate_cosine_similarity(question_terms, token, word_vectors):\n",
    "        cosine_similarity_score = 0\n",
    "        for term in question_terms:\n",
    "            if (term in word_vectors.vocab) and (token in word_vectors.vocab):                \n",
    "                score = word_vectors.similarity(token, term)\n",
    "                cosine_similarity_score += score\n",
    "            else:\n",
    "                cosine_similarity_score -= 1\n",
    "                continue\n",
    "        cosine_similarity_score /= len(question_terms)\n",
    "        return cosine_similarity_score           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    facts = AskQuestion().main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
